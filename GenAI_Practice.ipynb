{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP8GfS8PfRl/vRyjxBZdb6Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db1d504c83584eac8aa8b7a00cc9cda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_828be6fccb1b49628ef701ebe78d8ef3",
              "IPY_MODEL_b923bbafcdfb4b9f8658a3865e799614",
              "IPY_MODEL_6b372e6bc9f6482a8becca78dda31a44"
            ],
            "layout": "IPY_MODEL_f32ec9170ba84ee9a098107b91572b88"
          }
        },
        "828be6fccb1b49628ef701ebe78d8ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45615e7eea9e4c29832cc2ae7127c494",
            "placeholder": "​",
            "style": "IPY_MODEL_38db3c7163134ac08eb206a36935feee",
            "value": "100%"
          }
        },
        "b923bbafcdfb4b9f8658a3865e799614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d296187e124b6c8f49e8aa938f128f",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4340a074a8b341188a50dc0c2b274478",
            "value": 15
          }
        },
        "6b372e6bc9f6482a8becca78dda31a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945bf13076d1485bbb7ec1cd85dd480f",
            "placeholder": "​",
            "style": "IPY_MODEL_d9e8177e851f4cedb094e2d4244a463b",
            "value": " 15/15 [00:51&lt;00:00,  1.46it/s]"
          }
        },
        "f32ec9170ba84ee9a098107b91572b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45615e7eea9e4c29832cc2ae7127c494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38db3c7163134ac08eb206a36935feee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90d296187e124b6c8f49e8aa938f128f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4340a074a8b341188a50dc0c2b274478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "945bf13076d1485bbb7ec1cd85dd480f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e8177e851f4cedb094e2d4244a463b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aipractices/genai-application-collab-excercise/blob/main/GenAI_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Gen AI Application"
      ],
      "metadata": {
        "id": "KT2SqkJCx-_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Gen AI Application Architecture"
      ],
      "metadata": {
        "id": "j7EFW5hHCd56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gen AI Architecture\n",
        "\n",
        "Gen AI Architecture Consists of following components:\n",
        "\n",
        "![Gen AI Architecture](https://thinkuldeep.com/images/genai-artchitecture.jpg)\n",
        "\n",
        "\n",
        "### Gen AI User Interface - Front End\n",
        "This is the front of Gen AI application providing user interface which collect user inputs and present the response as per the business need. Eg. [ChatGPT Web App](https://chatgpt.com/)  \n",
        "\n",
        "### Gen AI Application - Backend\n",
        "This consists of GenAI application backend that accepts user inputs and converts them on prompts, and send them to further LLMs and get response from them, and return the response to front-end applications. It also has local memory and connected to knowlege base to improve the prompt.\n",
        "\n",
        "- Memory  - Local memory system to maintain cache for responses, and important metadata, context, and send with prompt to make it as a session, or continuous chat.\n",
        "- Knowlege Base - This is knowlege system, typically vector database as per the usecases, and it fetches the inforamtion, find closes match to input prompt, and augment the prompt, the improved promt then send to LLMs. Knowlege get's in the form of embedings.\n",
        "\n",
        "## Large Language Models\n",
        "These are GPT models trained on very large datasets, and many such models are avaiable on repositories like Hugging faces and others.   \n",
        "\n",
        "> Fine Tuning - This is technique to re-train and pre-trained generic model, to meet our business need."
      ],
      "metadata": {
        "id": "t_viFQwtC7pZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Developing First Gen AI Application"
      ],
      "metadata": {
        "id": "0Lflx5CAVxjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build our first Gen AI application, that takes a prompt and print the response return from LLM avaialble at Gemini APIs.\n",
        "\n",
        "Lets try the same with gemini model. We would API key for gemini.\n",
        "\n",
        "Follow the steps below.\n",
        "- Sign up on google.cloud.com, and go to https://console.cloud.google.com/\n",
        "- Enable Gemini APIs -  https://console.cloud.google.com/apis/library/generativelanguage.googleapis.com\n",
        "- Get API Key from Google AI Studio - https://console.cloud.google.com/apis/library/generativelanguage.googleapis.com\n",
        "\n",
        "https://ai.google.dev/gemini-api/docs/text-generation"
      ],
      "metadata": {
        "id": "5_sWLaElXRj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "def query_gemini(prompt):\n",
        "  client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      contents=[prompt]\n",
        "  )\n",
        "  return response.text\n",
        "\n",
        "prompt = \"Tell me about Kuldeep\"\n",
        "\n",
        "print(query_gemini(prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HKxIZl9rjKd",
        "outputId": "1fb2eaac-3bef-4f01-ab8c-d83fb2fc5134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To give you the best information about \"Kuldeep,\" I need a little more context.  \"Kuldeep\" is a fairly common name, particularly in India.  To help me narrow down who or what you're interested in, please tell me:\n",
            "\n",
            "*   **Are you thinking of a specific person?** If so, do you know anything else about them? For example, their last name, occupation, or any achievements they might be known for?\n",
            "*   **Are you interested in the meaning or origin of the name \"Kuldeep\" in general?**\n",
            "*   **Are you looking for something else entirely related to the word \"Kuldeep\"?**\n",
            "\n",
            "In the meantime, here's some general information that might be helpful:\n",
            "\n",
            "*   **Meaning of the name:** \"Kuldeep\" is a Hindu/Indian name that typically means \"light of the family\" or \"light of the clan.\" It comes from the Sanskrit words \"Kul\" (family/clan) and \"Deep\" (light/lamp).\n",
            "*   **Popularity:** The name is relatively popular in India and among the Indian diaspora.\n",
            "\n",
            "Once I have a better idea of what you're looking for, I can provide you with much more relevant information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving The Prompt - Prompt Engineering\n",
        "In the earlier example, you have seen the LLM responded with weard answers, because we not provide good context, and information.  \n",
        "\n",
        "\n",
        "Gen AI response is very much depend what we ask in the prompt. There are\n",
        "verious techniques to improve the prompt, by providing GPT a persona, context,\n",
        "provide one or more examples on how do we want the response. These are call one-shot, few-shot prompting.  Generally it make take multiple attempts to get the prompt right, and we can have chain of prompt like conversations with people to get it right, or provding step by step intructions to LLM to reach to output. some call these chain of thought, or tree of thoght techniques.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fac5lTrED1pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "def run_chatbot():\n",
        "    print(\"Hello! I am thinkuldeep, how can I help you! Type 'quit' to exit.\")\n",
        "    chat_history = []\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"thinkuldeep: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = chat.send_message(user_input)\n",
        "        print(f\"thinkuldeep: {response.text}\")\n",
        "\n",
        "# Start the chatbot\n",
        "run_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHUUZNwoRIwl",
        "outputId": "499b1f88-e1d5-4696-8b99-6c8307b03dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am thinkuldeep, how can I help you! Type 'quit' to exit.\n",
            "You: test\n",
            "thinkuldeep: Understood. You've entered \"test\". How can I help you with that?  Are you:\n",
            "\n",
            "*   **Testing if I'm working?** (I am!)\n",
            "*   **Wanting to test me on something specific?** (e.g., a math problem, a grammar question, a code snippet)\n",
            "*   **Using this as a placeholder for a future question?**\n",
            "*   **Something else entirely?**\n",
            "\n",
            "Let me know what you'd like to do.\n",
            "\n",
            "You: quit\n",
            "thinkuldeep: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "people call all these technieques as prompt engieering, but I think writing a prompt is art, art of communication I will explain it in a seperate article. However scope of this article is to build GenAI based application, so not focusing much on so called prompt engieering.\n",
        "\n",
        "Assuming you are very good in write prompt, but still LLM may not respond well as we exact. For example, for knowing summary of infromation about individual \"Kuldeep\" may not be known by LLMs, but if our Gen AI application first get some more inforamation kuldeep and send it LLM along with prompt, and then it would respond better. Let's uderstand this better in next section."
      ],
      "metadata": {
        "id": "NQ0OrSRUMyrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrival Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "_Hgxb0jPtYlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLMs are trained on huge dataset, but may still know about responding perticular information about individuals, specific usecases. In such cases RAG is a techniques helps retrieve contextual information from knowlege base, and augment the prompt and send it for generation to LLM."
      ],
      "metadata": {
        "id": "tnF3FCMdH4jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "\n",
        "import requests\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def retrive(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    text_content = \"\"\n",
        "    for paragraph in soup.find_all(\"p\"):\n",
        "        text_content += paragraph.get_text(strip=True) + \"\\n\"\n",
        "\n",
        "    return text_content\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    return f\"Error fetching URL: {e}\"\n",
        "  except Exception as e:\n",
        "    return f\"An error occurred: {e}\"\n",
        "\n",
        "def augment(prompt, context):\n",
        "  return f\"{prompt} where context is {context}\"\n",
        "\n",
        "def generation(prompt):\n",
        "\n",
        "  client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "      model=\"gemini-2.0-flash\",\n",
        "      contents=[prompt]\n",
        "  )\n",
        "  return response.text\n",
        "\n",
        "prompt = \"Tell me about Kuldeep\"\n",
        "\n",
        "context = retrive(\"https://thinkuldeep.com/about/\")\n",
        "\n",
        "print(generation(augment(prompt, context)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8P48UUSSUBfF",
        "outputId": "e13f27a3-e51e-483a-a0c8-dd9c735036f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Okay, here's a summary of Kuldeep's professional and personal profile, organized according to the categories provided:\n",
            "\n",
            "**📨 Contact Me**\n",
            "\n",
            "*   **LinkedIn:** kuldeep-reck\n",
            "*   **X (Twitter):** thinkuldeep\n",
            "*   **Instagram:** thinkuldeep\n",
            "*   **Facebook:** kuldeep.reck\n",
            "*   **Personal Email:** thinkuldeep@gmail.com\n",
            "*   **Official Email:** kuldeeps@thoughtworks.com\n",
            "\n",
            "**📃 My Resume**\n",
            "\n",
            "*   **Current Role:** Global Emerging Technology Leader and Principal Consultant at Thoughtworks.\n",
            "*   **Past Role:** Director, Technology at Nagarro (13 years, various roles from developer).\n",
            "*   **Education:**\n",
            "    *   B.Tech (Hons) in Computer Science and Engineering, National Institute of Technology, Kurukshetra.\n",
            "    *   Schooling from a small town in Rajasthan.\n",
            "*   **Key Skills & Expertise:**\n",
            "    *   Emerging Technologies: XR (AR/VR/MR), IoT, Metaverse, Blockchain.\n",
            "    *   Software Development: CICD, TDD, Automation Testing, XP, Cloud-Native Architectures, Microservices.\n",
            "    *   Data Projects: Estimations, Forecasting, Optimization.\n",
            "    *   Practices: XR, IoT\n",
            "    *   Leadership and Evangelism.\n",
            "\n",
            "**🎗️ Communities I Support**\n",
            "\n",
            "*   **Mentorship:** PeriFerry (trans community), Dream Mentor, tealfeed.com, Advisor to young entrepreneurs.\n",
            "*   **Volunteer:** Various non-profit initiatives.\n",
            "*   **Speaker/Judge/Mentor:** Smart India Hackathon, NASSCOM, IEEE, UN’s ITU-T Study Group 20.\n",
            "*   XR Practices, IOT Practices, Responsible Metaverse Alliance, World Metaverse Council, industry4o, XROM, XTIC.\n",
            "\n",
            "**🛟 My Life Mantras**\n",
            "\n",
            "*   \"When you have confusion on how to start, then don't wait, just start.\"\n",
            "*   \"Leadership is a feeling, learn to lead ownself, and be your own leader.\"\n",
            "*   \"You can do much more than what you think.\"\n",
            "*   \"Winning an argument is not really a Winning.\"\n",
            "*   \"We explore more of us by giving it away to others.\"\n",
            "\n",
            "**🗣️ What Others Say About Me**\n",
            "\n",
            "*   Consistently described as a technical leader, visionary, and expert in emerging technologies (AR/VR, XR, IoT, Metaverse).\n",
            "*   Praised for his deep and broad knowledge, hands-on approach, and ability to explain complex concepts.\n",
            "*   Recognized for his leadership skills, ability to motivate teams, and commitment to sharing knowledge.\n",
            "*   Appreciated for his calm demeanor, communication skills, and ability to bring people together.\n",
            "*   Valued for his contributions to successful projects and his ability to translate product requirements into execution.\n",
            "*   Considered a great mentor, team builder, and friend.\n",
            "*   Cited for promoting autonomous teams, D&I, and sustainability.\n",
            "\n",
            "**🐦‍🔥️ My Inventions**\n",
            "\n",
            "*   Innovative work grant patents and published.\n",
            "\n",
            "**📚 My Books**\n",
            "\n",
            "*   Author of \"Exploring the Metaverse,\" \"MyThoughtworkings.\"\n",
            "*   Reviewer and writer of forewords for other books.\n",
            "\n",
            "**🏆 My Awards**\n",
            "\n",
            "*   India Achievers’ Award 2022.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "\n",
        "import requests\n",
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "client = genai.Client(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
        "\n",
        "def retrive(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    text_content = \"\"\n",
        "    for paragraph in soup.find_all(\"p\"):\n",
        "        text_content += paragraph.get_text(strip=True) + \"\\n\"\n",
        "\n",
        "    return text_content\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    return f\"Error fetching URL: {e}\"\n",
        "  except Exception as e:\n",
        "    return f\"An error occurred: {e}\"\n",
        "\n",
        "def augment(prompt, context):\n",
        "  return f\"Context for all future communication {context}\"\n",
        "\n",
        "context = retrive(\"https://thinkuldeep.com/about/\")\n",
        "\n",
        "def run_chatbot():\n",
        "    print(\"Hello! ask me about Kuldeep Singh! Type 'quit' to exit.\")\n",
        "    chat_history = []\n",
        "\n",
        "    chat.send_message(augment(\"\", context))\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"thinkuldeep: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        response = chat.send_message(user_input)\n",
        "        print(f\"thinkuldeep: {response.text}\")\n",
        "\n",
        "# Start the chatbot\n",
        "run_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6-2J8JnVmC2",
        "outputId": "0de8af6b-cb0e-4709-a9ce-982b3ec9505e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Hello! ask me about Kuldeep Singh! Type 'quit' to exit.\n",
            "You: where does kuldeep work\n",
            "thinkuldeep: Kuldeep is currently associated with Thoughtworks as Global Emerging Technology Leader and Principal Consultant. He previously worked with Nagarro for 13 years.\n",
            "\n",
            "You: what contact number of kuldeep\n",
            "thinkuldeep: I do not have access to Kuldeep's personal contact information. The provided text includes his email addresses:\n",
            "\n",
            "*   **Personal:** thinkuldeep@gmail.com\n",
            "*   **Official:** kuldeeps@thoughtworks.com\n",
            "\n",
            "You can try reaching out to him through these email addresses or via his social media profiles listed:\n",
            "\n",
            "*   LinkedIn: kuldeep-reck\n",
            "*   X (Twitter): thinkuldeep\n",
            "*   Instagram: thinkuldeep\n",
            "*   Facebook: kuldeep.reck\n",
            "\n",
            "You: quit\n",
            "thinkuldeep: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Embeddings\n",
        "\n"
      ],
      "metadata": {
        "id": "lb5qfy-jXe3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings are the vector representation of a sentence, and used to find relation with a query and data. Like in below example there are some titles for specific content. Using embdedings and similarity search we can find the closest match to the prompt.   "
      ],
      "metadata": {
        "id": "9hESil7OqIus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4 pandas numpy\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "pages = [\n",
        "  {\n",
        "    \"title\": \"Open-sources and Community Applications\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/open-sources/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Live Streaming, Webinars\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/streaming/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Patents Granted\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/patents/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Awards received and public coverage\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/recognitions/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Me, my family and some moments, travel and trips\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/moments/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Book foreword, reviewed and authored\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/books/\"\n",
        "  }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(pages)\n",
        "df.columns = ['Title', 'Url']\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "model = 'models/embedding-001'\n",
        "def pageEmbeddings(title, text):\n",
        "  return genai.embed_content(model=model,\n",
        "                             content=text,\n",
        "                             task_type=\"retrieval_document\",\n",
        "                             title=title)[\"embedding\"]\n",
        "\n",
        "def findBestPage(query, dataframe):\n",
        "  query_embedding = genai.embed_content(model=model,\n",
        "                                        content=query,\n",
        "                                        task_type=\"retrieval_query\")\n",
        "  dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding[\"embedding\"])\n",
        "  idx = np.argmax(dot_products)\n",
        "  return dataframe.iloc[idx]['Url']\n",
        "\n",
        "\n",
        "prompt = \"Tell me in brief Kuldeep's travels\"\n",
        "\n",
        "df['Embeddings'] = df.apply(lambda row: pageEmbeddings(row['Title'], row['Url']), axis=1)\n",
        "\n",
        "bestPage = findBestPage(prompt, df)\n",
        "\n",
        "print(bestPage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "z88pwevvJyLv",
        "outputId": "b5fe1c8f-2f1b-415e-84e4-85f24e81b841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mhttps://thinkuldeep.com/about/moments/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing RAG using Similaliry Search on Embeddings\n",
        "\n",
        "Let's build a chatbot, that gives better result based on best match and additional context. Ask specific questions about Kuldeep."
      ],
      "metadata": {
        "id": "ABWL5xANpkwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4 pandas numpy\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "import google.generativeai as genai\n",
        "\n",
        "pages = [\n",
        "  {\n",
        "    \"title\": \"Open-sources and Community Applications\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/open-sources/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Live Streaming, Webinars\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/streaming/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Patents Granted\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/patents/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Awards received and public coverage, news\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/recognitions/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Me, my family and some moments, travel and trips\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/moments/\"\n",
        "  },\n",
        "  {\n",
        "    \"title\": \"Book foreword, reviewed and authored\",\n",
        "    \"content\": \"https://thinkuldeep.com/about/books/\"\n",
        "  }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(pages)\n",
        "df.columns = ['Title', 'Url']\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "model = 'models/embedding-001'\n",
        "def pageEmbeddings(title, text):\n",
        "  return genai.embed_content(model=model,\n",
        "                             content=text,\n",
        "                             task_type=\"retrieval_document\",\n",
        "                             title=title)[\"embedding\"]\n",
        "\n",
        "def findBestPage(query, dataframe):\n",
        "  query_embedding = genai.embed_content(model=model,\n",
        "                                        content=query,\n",
        "                                        task_type=\"retrieval_query\")\n",
        "  dot_products = np.dot(np.stack(dataframe['Embeddings']), query_embedding[\"embedding\"])\n",
        "  idx = np.argmax(dot_products)\n",
        "  return dataframe.iloc[idx]['Url']\n",
        "\n",
        "df['Embeddings'] = df.apply(lambda row: pageEmbeddings(row['Title'], row['Url']), axis=1)\n",
        "\n",
        "def retrive(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    text_content = \"\"\n",
        "    for paragraph in soup.find_all(\"p\"):\n",
        "        text_content += paragraph.get_text(strip=True) + \"\\n\"\n",
        "    for h3 in soup.find_all(\"h3\"):\n",
        "        text_content += h3.get_text(strip=True) + \"\\n\"\n",
        "    #print(text_content)\n",
        "    return text_content\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    return f\"Error fetching URL: {e}\"\n",
        "  except Exception as e:\n",
        "    return f\"An error occurred: {e}\"\n",
        "\n",
        "def augment(prompt, context):\n",
        "  return f\"{prompt}. Here is the context: {context}\"\n",
        "\n",
        "context = retrive(\"https://thinkuldeep.com/about/\")\n",
        "\n",
        "def run_chatbot():\n",
        "    print(\"Hello! ask me about Kuldeep Singh! Type 'quit' to exit.\")\n",
        "    chat_history = []\n",
        "\n",
        "    chat.send_message(augment(\"\", context))\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"thinkuldeep: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        bestPageMatching = findBestPage(user_input, df)\n",
        "      #  print(f\"bestPageMatching: {bestPageMatching}\")\n",
        "        response = chat.send_message(augment(user_input, retrive(bestPageMatching)))\n",
        "        print(f\"thinkuldeep: {response.text}\")\n",
        "\n",
        "run_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "collapsed": true,
        "id": "CK4ntI2mpwJq",
        "outputId": "1b2b70ec-addd-4066-ba24-b547404d685d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Hello! ask me about Kuldeep Singh! Type 'quit' to exit.\n",
            "You: tell me about kuldeep community contribution\n",
            "thinkuldeep: Okay, based on the provided information, here's a summary of Kuldeep's community contributions, primarily focusing on open-source projects:\n",
            "\n",
            "Kuldeep contributes to the open-source community through the following projects:\n",
            "\n",
            "*   **OpenThread Commissioner Implementation in Java:** This project provides a guide for developers to build an external Commissioner in Java, bridging the gap in the OpenThread project.\n",
            "*   **MQTT-Remote:** A web-based remote control for an LED, syncing a web button with a hardware button.\n",
            "*   **ModelViewer:** WebXR and 3D printing demonstrations showcasing the possibilities of WebXR.\n",
            "*   **3D Book:** An implementation of adding and turning pages in a book like a real book using code.\n",
            "*   **Arium — An Automation framework for Unity/XR:** Part of the core development team and a reviewer for this framework designed for writing automation tests in Unity, specifically for XR (AR/VR) applications.\n",
            "*   **DecoAR — Decorate the world with XR:** An app for extending decoration at home, office, or any place by tracking images and overlaying content using smart glasses.\n",
            "*   **Pair Generator - Conducting feedback made easy:** A tool to generate pairs for organizing 1-1 feedback sessions, saving manual effort.\n",
            "*   **Why Worry - Life is simple, we make it complex:** An app designed to reduce anxiety by providing strategies for balancing life.\n",
            "*   **Image-evaluator - online assessment tool:** An app that evaluates images online with simple JavaScript.\n",
            "\n",
            "**Key Themes:**\n",
            "\n",
            "*   **XR (AR/VR) Focus:** Several projects (Arium, DecoAR, ModelViewer) highlight his strong interest and expertise in extended reality technologies.\n",
            "*   **Open Source Engagement:** He actively participates in creating and maintaining open-source tools and resources.\n",
            "*   **Automation & Efficiency:** Projects like Pair Generator demonstrate his focus on creating tools to improve efficiency in team processes.\n",
            "*   **Practical Applications:** The projects often address real-world problems and offer practical solutions.\n",
            "*   **Web Technologies:** Many of the listed programs are web-based.\n",
            "*   **Uses of Github:** It can be said, that Kuldeep uses Github to post community contribution.\n",
            "\n",
            "You: quit\n",
            "thinkuldeep: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "_Osan7jOxDGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D-I-RxnLxI2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "basemodel = \"models/gemini-1.5-flash-001-tuning\"\n",
        "\n",
        "trainingdata = [\n",
        "    {\"text_input\": \"What is Gen AI\", \"output\": \"Good Question! Gen AI is branch of AI. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is LLM\", \"output\": \"Good Question! LLM means Large Language Model. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is Embeddings in Gen AI\", \"output\": \"Good Question! Embeddings is a vector representations. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is Fine Tuning\", \"output\": \"Good Question! retraining model specific dataset. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is prompt engineering\", \"output\": \"Good Question! It is about writing better prompts. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is RAG\", \"output\": \"Good Question! Retrieval Augmented Generation (RAD) is technique to augment prompts with externanly retrived data. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is a Transformer in Gen AI\", \"output\": \"Good Question! It is an LLM architecure. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is zero-shot learning in AI\", \"output\": \"Good Question! no example given in prompt. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is hallucination in Gen AI\", \"output\": \"Good Question! Gen AI providing false information. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is overfitting\", \"output\": \"Good Question! Data is too well trained, not training on unknowns . All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is token limit in LLM\", \"output\": \"Good Question! Maximum token for query. All the best - thinkuldeep.com\"},\n",
        "    {\"text_input\": \"What is unsupervised learning in AI\", \"output\": \"Good Question! learnings from unlabeled dataset. All the best - thinkuldeep.com\"}\n",
        "]\n",
        "\n",
        "operation = genai.create_tuned_model(\n",
        "    display_name=\"thinkuldeep\",\n",
        "    source_model=basemodel,\n",
        "    epoch_count=5,\n",
        "    batch_size=4,\n",
        "    learning_rate=0.001,\n",
        "    training_data=trainingdata,)\n",
        "\n",
        "for status in operation.wait_bar():\n",
        "  time.sleep(10)\n",
        "\n",
        "print(operation.result());\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370,
          "referenced_widgets": [
            "db1d504c83584eac8aa8b7a00cc9cda3",
            "828be6fccb1b49628ef701ebe78d8ef3",
            "b923bbafcdfb4b9f8658a3865e799614",
            "6b372e6bc9f6482a8becca78dda31a44",
            "f32ec9170ba84ee9a098107b91572b88",
            "45615e7eea9e4c29832cc2ae7127c494",
            "38db3c7163134ac08eb206a36935feee",
            "90d296187e124b6c8f49e8aa938f128f",
            "4340a074a8b341188a50dc0c2b274478",
            "945bf13076d1485bbb7ec1cd85dd480f",
            "d9e8177e851f4cedb094e2d4244a463b"
          ]
        },
        "collapsed": true,
        "id": "Mle2m1lEQqug",
        "outputId": "247b6688-388d-4bc2-ab8b-83aeaaa5254e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db1d504c83584eac8aa8b7a00cc9cda3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TunedModel(name='tunedModels/thinkuldeep-1t5bnlclgmt4eg3pgdkvbyaqmms5',\n",
            "           source_model='models/gemini-1.5-flash-001-tuning',\n",
            "           base_model='models/gemini-1.5-flash-001-tuning',\n",
            "           display_name='thinkuldeep',\n",
            "           description='',\n",
            "           temperature=1.0,\n",
            "           top_p=0.95,\n",
            "           top_k=64,\n",
            "           state=<State.ACTIVE: 2>,\n",
            "           create_time=datetime.datetime(2025, 5, 16, 6, 50, 16, 356464, tzinfo=datetime.timezone.utc),\n",
            "           update_time=datetime.datetime(2025, 5, 16, 6, 51, 4, 78592, tzinfo=datetime.timezone.utc),\n",
            "           tuning_task=TuningTask(start_time=datetime.datetime(2025, 5, 16, 6, 50, 16, 508254, tzinfo=datetime.timezone.utc),\n",
            "                                  complete_time=datetime.datetime(2025, 5, 16, 6, 51, 4, 78592, tzinfo=datetime.timezone.utc),\n",
            "                                  snapshots=[...],\n",
            "                                  hyperparameters=Hyperparameters(epoch_count=5,\n",
            "                                                                  batch_size=4,\n",
            "                                                                  learning_rate=0.001)),\n",
            "           reader_project_numbers=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Fine Tuned Model"
      ],
      "metadata": {
        "id": "DQo84dEAJ4OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "model = genai.GenerativeModel(model_name=\"tunedModels/thinkuldeep-1t5bnlclgmt4eg3pgdkvbyaqmms5\");\n",
        "\n",
        "prompt = \"What is Gen AI\"\n",
        "\n",
        "print(model.generate_content(prompt).text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AAqRKzQIJzQ7",
        "outputId": "2eb8441f-faed-44eb-d292-05a730a16964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gen AI is a type of AI that is used to generate different text formats. All the best - thinkuldeep.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "sPUHA_Ro3YNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This completes the Gen AI in practice."
      ],
      "metadata": {
        "id": "PsEFuVH23cRy"
      }
    }
  ]
}